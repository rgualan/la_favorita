{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ff2fd268-839a-4483-8681-3c26914f7d9b",
    "_uuid": "89210ac8934aeaeeaaa2b194439c712aded9e688"
   },
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "75fd2f9a-7297-4203-b8f7-1502f66e0c9e",
    "_kg_hide-output": true,
    "_uuid": "54cda7088daf8d27c5627cb80f9bef15fa30f6e7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA MANIPULATION\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import random \n",
    "import datetime # manipulating date formats\n",
    "\n",
    "# VIZUALIZATION\n",
    "import matplotlib.pyplot as plt # basic plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# SUPERVISED LEARNING\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing train data\n",
    "\n",
    "Try reducing the dataset size by choosing a subset of stores/items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtypes = {'id':'int64', 'item_nbr':'int32', 'store_nbr':'int8', 'onpromotion':str}\n",
    "\n",
    "if False:\n",
    "    # Reading train data\n",
    "    train = pd.read_csv('../input/train.csv', dtype=dtypes, parse_dates=['date'])\n",
    "\n",
    "    # Filter out some stores\n",
    "    #sales = pd.read_csv('../input/processed/sales+.csv', parse_dates=['date'])\n",
    "    u_stores = train.store_nbr.unique()\n",
    "    random.seed(115599)\n",
    "    random_stores = sorted(u_stores[random.sample(range(len(u_stores)), 2) ])\n",
    "\n",
    "    train = train[lambda df: (df.store_nbr.isin(random_stores)) & (df.date>=\"2015-01-01\")]\n",
    "    train.to_csv('../input/processed/train_min.csv',index=False)\n",
    "    \n",
    "\n",
    "    # For test data\n",
    "    test = pd.read_csv('../input/test.csv', dtype=dtypes, parse_dates=['date'])\n",
    "    test = test[lambda df: (df.store_nbr.isin(random_stores))]\n",
    "    test.to_csv('../input/processed/test_min.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "6eccd50b-c197-4fbb-8f21-dac64e7165d4",
    "_uuid": "2d3b84468f9166e001f7ddf20700ac61030101ee",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading train\n",
    "train = pd.read_csv('../input/processed/train_min.csv', dtype=dtypes, parse_dates=['date'])\n",
    "#train = pd.read_csv('../input/processed/train.csv', dtype=dtypes, parse_dates=['date'])\n",
    "\n",
    "def merge_with_extra_datasets(df):\n",
    "    # Reading extra datasets\n",
    "    sales = pd.read_csv('../input/processed/sales+.csv', parse_dates=['date']) # (completed) sales \n",
    "    items = pd.read_csv('../input/items.csv')\n",
    "\n",
    "    # Merging datasets\n",
    "    df = pd.merge(df, items, how='left')\n",
    "    df = pd.merge(df, sales,how='left')\n",
    "    \n",
    "    df.drop(['lag_7','lag_annual'],1,inplace=True) # Unnecessary - from transaction prediction\n",
    "    \n",
    "    del sales, items\n",
    "    \n",
    "    return df \n",
    "    \n",
    "train = merge_with_extra_datasets(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date        store_nbr\n",
       "2016-01-03  21           2060\n",
       "            32            986\n",
       "2016-01-04  21           1872\n",
       "Name: item_nbr, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.transactions.isnull()].groupby(['date','store_nbr']).item_nbr.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)\n",
    "#print([(c,train[c].isnull().sum()) for c in train.columns])\n",
    "\n",
    "## There are a couple of days for which there are not transactions. \n",
    "## Since they are only two days, it might be safe to ignore them "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train[train.family=='CLEANING'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform target\n",
    "def transform_target(df):\n",
    "    df.loc[df.unit_sales < 0., 'unit_sales'] = 0.\n",
    "    df['unit_sales'] = np.log1p(df.unit_sales)\n",
    "    return df\n",
    "    \n",
    "## Transform onpromotion\n",
    "def transform_onpromotion(df):\n",
    "    df['onpromotion'] = df['onpromotion'].map({'False': 0, 'True': 1})\n",
    "    return df\n",
    "\n",
    "## Some features were not very useful: year,month,day\n",
    "def add_date_features(df):\n",
    "    #df['year'] = df['date'].dt.year\n",
    "    #df['month'] = df['date'].dt.month\n",
    "    #df['day'] = df['date'].dt.day\n",
    "    df['week'] = df['date'].dt.week\n",
    "    df['dow'] = df['date'].dt.dayofweek\n",
    "    df['dayofyear'] = df['date'].dt.dayofyear\n",
    "    df['dayoff']=[x in [5,6] for x in df.dow] ## Weekends\n",
    "    return df\n",
    "\n",
    "# Add weight feature (from perishable feature) \n",
    "# for calculating error metric\n",
    "def add_weight_feature(df):\n",
    "    df['perishable_w'] = df['perishable'].map({0:1.0, 1:1.25})\n",
    "    return df\n",
    "\n",
    "\n",
    "train = transform_target(train)\n",
    "train = transform_onpromotion(train)\n",
    "train = add_date_features(train)\n",
    "train = add_weight_feature(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2263890 entries, 0 to 2268807\n",
      "Data columns (total 20 columns):\n",
      "id              int64\n",
      "date            datetime64[ns]\n",
      "store_nbr       int8\n",
      "item_nbr        int32\n",
      "unit_sales      float64\n",
      "onpromotion     int64\n",
      "family          object\n",
      "class           int64\n",
      "perishable      int64\n",
      "transactions    float64\n",
      "city            object\n",
      "state           object\n",
      "type            object\n",
      "cluster         float64\n",
      "dcoilwtico      float64\n",
      "week            int64\n",
      "dow             int64\n",
      "dayofyear       int64\n",
      "dayoff          bool\n",
      "perishable_w    float64\n",
      "dtypes: bool(1), datetime64[ns](1), float64(5), int32(1), int64(7), int8(1), object(4)\n",
      "memory usage: 323.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Categorical features\n",
    "def encode(df, column) -> pd.DataFrame:\n",
    "    one_hot = pd.get_dummies(df[column], drop_first=True, prefix=column)\n",
    "    #return (one_hot - one_hot.mean()) / one_hot.std()\n",
    "    return one_hot\n",
    "\n",
    "def encode_categorical_features(df):\n",
    "    #cat_columns = ['item_nbr']\n",
    "    cat_columns = ['family']\n",
    "    \n",
    "    for column in cat_columns:\n",
    "        column_enc = encode(df, column)\n",
    "        df = pd.concat([df,column_enc], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "#train = encode_categorical_features(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2263890 entries, 0 to 2268807\n",
      "Data columns (total 20 columns):\n",
      "id              int64\n",
      "date            datetime64[ns]\n",
      "store_nbr       int8\n",
      "item_nbr        int32\n",
      "unit_sales      float64\n",
      "onpromotion     int64\n",
      "family          object\n",
      "class           int64\n",
      "perishable      int64\n",
      "transactions    float64\n",
      "city            object\n",
      "state           object\n",
      "type            object\n",
      "cluster         float64\n",
      "dcoilwtico      float64\n",
      "week            int64\n",
      "dow             int64\n",
      "dayofyear       int64\n",
      "dayoff          bool\n",
      "perishable_w    float64\n",
      "dtypes: bool(1), datetime64[ns](1), float64(5), int32(1), int64(7), int8(1), object(4)\n",
      "memory usage: 323.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_cols = [c for c in train.columns if not c.startswith('class_')]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Count items by store\n",
    "train.groupby(['store_nbr','item_nbr']).unit_sales.size().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing store 32...\n",
      "            unit_sales     lag_7\n",
      "unit_sales    1.000000  0.575435\n",
      "lag_7         0.575435  1.000000\n",
      "Processing store 21...\n",
      "            unit_sales     lag_7\n",
      "unit_sales    1.000000  0.646389\n",
      "lag_7         0.646389  1.000000\n"
     ]
    }
   ],
   "source": [
    "def add_lag_features(df):\n",
    "    \n",
    "    u_store = df.store_nbr.unique()\n",
    "    df['lag_7'] = np.nan\n",
    "    df_2 = pd.DataFrame()\n",
    "\n",
    "    for s in u_store:\n",
    "        print(\"Processing store %d...\"%(s))\n",
    "        tmp = df[df.store_nbr==s]\n",
    "        dates_range = pd.date_range(tmp.date.min(), tmp.date.max())\n",
    "        u_items = tmp.item_nbr.unique()\n",
    "\n",
    "        # Reindex by date and item\n",
    "        tmp.set_index([\"date\", \"item_nbr\"], inplace=True)\n",
    "        tmp = tmp.reindex(\n",
    "            pd.MultiIndex.from_product(\n",
    "                [dates_range, u_items],\n",
    "                names=[\"date\", \"item_nbr\"]\n",
    "            )\n",
    "        )\n",
    "        tmp.sort_index(inplace=True)\n",
    "\n",
    "        # Create lag features\n",
    "        tmp['lag_7'] = tmp['unit_sales'].shift(7*len(u_items))\n",
    "\n",
    "        # Delete temporal df \n",
    "        tmp = tmp.reset_index()\n",
    "\n",
    "        # Drop nan in transactions column\n",
    "        tmp.dropna(subset=['unit_sales'], inplace=True)\n",
    "\n",
    "        # Correlation coefficient\n",
    "        print(tmp[['unit_sales','lag_7']].corr())\n",
    "\n",
    "        df_2 = pd.concat([df_2,tmp])\n",
    "        \n",
    "    return df_2\n",
    "\n",
    "    \n",
    "train = add_lag_features(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "Ignore items which are not in the test data\n",
    "It is necessary to create a stage 2 for creating lag features from seasonal data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the missing data\n",
    "\n",
    "This is necessary in this point, because in the next step a lot of rows will be injected to provide complete time series."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "md = [(c,train[c].isnull().sum()) for c in train.columns]\n",
    "\n",
    "for a in md:\n",
    "    if a[1]>0:\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop nan in transactions column\n",
    "#train.dropna(subset=['unit_sales'], inplace=True)\n",
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NWRMSLE(y, pred, w):\n",
    "    return metrics.mean_squared_error(y, pred, sample_weight=w)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['onpromotion',\n",
       " 'perishable',\n",
       " 'transactions',\n",
       " 'dcoilwtico',\n",
       " 'week',\n",
       " 'dow',\n",
       " 'dayofyear',\n",
       " 'dayoff',\n",
       " 'lag_7']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [c for c in train if c not in ['id','date','store_nbr','city','state','type','cluster',\n",
    "                                      'item_nbr','family','class','perishable_w',\n",
    "                                      'unit_sales']]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = train.loc[(train.date<'2017-08-01') & (train.date>='2016-01-01')]\n",
    "X2 = train.loc[(train.date>='2017-08-01')]\n",
    "\n",
    "target_column = 'unit_sales' \n",
    "y1 = X1[target_column].values\n",
    "y2 = X2[target_column].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "method =  1\n",
      "Multilayer perceptron (MLP) neural network 01\n",
      "Error: 0.628859\n",
      "\n",
      "method =  2\n",
      "Bagging Regressor 01\n",
      "Error: 0.615988\n",
      "\n",
      "method =  3\n",
      "GradientBoosting 01\n",
      "Error: 0.613598\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "np.random.seed(1122)\n",
    "\n",
    "number_regressors_to_test = 3\n",
    "for method in range(1, number_regressors_to_test+1):\n",
    "    print('\\nmethod = ', method)\n",
    "    \n",
    "    if (method==1):\n",
    "        print('Multilayer perceptron (MLP) neural network 01')\n",
    "        str_method = 'MLP model01'    \n",
    "        r = MLPRegressor(hidden_layer_sizes=(3,), max_iter=100)\n",
    "    if (method==2):\n",
    "        print('Bagging Regressor 01')\n",
    "        str_method = 'BaggingRegressor01'\n",
    "        r = BaggingRegressor(DecisionTreeRegressor(max_depth=6,max_features=0.85))\n",
    "    if (method==3):\n",
    "        print('GradientBoosting 01')\n",
    "        str_method = 'GradientBoosting01'\n",
    "        r = GradientBoostingRegressor()        \n",
    "\n",
    "    r.fit(X1[cols], y1)\n",
    "    yh2 = r.predict(X2[cols])\n",
    "    #X2['prediction_%d'%method] = yh2\n",
    "    m = NWRMSLE(y2, yh2, X2['perishable_w'])\n",
    "\n",
    "\n",
    "    print(\"Error: %f\" % (m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>perishable</th>\n",
       "      <th>transactions</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>week</th>\n",
       "      <th>dow</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayoff</th>\n",
       "      <th>lag_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>919437</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.498282</td>\n",
       "      <td>36.97</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919441</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.498282</td>\n",
       "      <td>36.97</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919443</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.498282</td>\n",
       "      <td>36.97</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.791759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919452</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.498282</td>\n",
       "      <td>36.97</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919453</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.498282</td>\n",
       "      <td>36.97</td>\n",
       "      <td>53.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.098612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        onpromotion  perishable  transactions  dcoilwtico  week  dow  \\\n",
       "919437          0.0         0.0      6.498282       36.97  53.0  5.0   \n",
       "919441          0.0         0.0      6.498282       36.97  53.0  5.0   \n",
       "919443          0.0         0.0      6.498282       36.97  53.0  5.0   \n",
       "919452          0.0         0.0      6.498282       36.97  53.0  5.0   \n",
       "919453          0.0         0.0      6.498282       36.97  53.0  5.0   \n",
       "\n",
       "        dayofyear dayoff     lag_7  \n",
       "919437        2.0   True  1.609438  \n",
       "919441        2.0   True  1.098612  \n",
       "919443        2.0   True  1.791759  \n",
       "919452        2.0   True  1.609438  \n",
       "919453        2.0   True  1.098612  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1[cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improvements:\n",
    "- Initial: 0.79\n",
    "- lag_7: 0.61"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions for test data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Train best method\n",
    "np.random.seed(1122)\n",
    "r = GradientBoostingRegressor()   \n",
    "r.fit(X1[cols], y1)\n",
    "yh2 = r.predict(X2[cols])\n",
    "m = NWRMSLE(y2, yh2, X2['perishable_w'])\n",
    "print(\"Error: %f\" % (m))\n",
    "\n",
    "#import pickle\n",
    "#pickle.dump(r, open('../input/models/simple.sav', 'wb'))\n",
    "#loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/processed/train_from2017.csv', dtype=dtypes, parse_dates=['date'])\n",
    "train.set_index(['date','store_nbr','item_nbr'], inplace=True)\n",
    "\n",
    "test = pd.read_csv('../input/processed/test_min.csv', dtype=dtypes, parse_dates=['date'])\n",
    "test = merge_with_extra_datasets(test)\n",
    "\n",
    "test = transform_onpromotion(test)\n",
    "test = add_date_features(test)\n",
    "test = add_weight_feature(test)\n",
    "#test = add_lag_features(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem detected:\n",
    "\n",
    "Some time series (store-item) in the test dataset do not exist in the training dataset. This is a huge problem for the lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">2017-08-09</th>\n",
       "      <th>3</th>\n",
       "      <th>96995</th>\n",
       "      <td>124780231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>96995</th>\n",
       "      <td>124786783</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>96995</th>\n",
       "      <td>124789082</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <th>96995</th>\n",
       "      <td>124835745</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <th>96995</th>\n",
       "      <td>124851075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <th>96995</th>\n",
       "      <td>124853825</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <th>96995</th>\n",
       "      <td>124859062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <th>96995</th>\n",
       "      <td>124861771</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id  unit_sales onpromotion\n",
       "date       store_nbr item_nbr                                   \n",
       "2017-08-09 3         96995     124780231         1.0       False\n",
       "           6         96995     124786783         1.0       False\n",
       "           7         96995     124789082         1.0       False\n",
       "           36        96995     124835745         1.0       False\n",
       "           44        96995     124851075         1.0       False\n",
       "           45        96995     124853825         2.0       False\n",
       "           47        96995     124859062         1.0       False\n",
       "           48        96995     124861771         1.0       False"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train.index.get_level_values('date')=='2017-08-09') & (train.index.get_level_values('item_nbr')==96995) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "      <th>transactions</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>week</th>\n",
       "      <th>dow</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayoff</th>\n",
       "      <th>perishable_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125575060</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>21</td>\n",
       "      <td>96995</td>\n",
       "      <td>0</td>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>228</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901</th>\n",
       "      <td>125617971</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>32</td>\n",
       "      <td>96995</td>\n",
       "      <td>0</td>\n",
       "      <td>GROCERY I</td>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>228</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id       date  store_nbr  item_nbr  onpromotion     family  \\\n",
       "0     125575060 2017-08-16         21     96995            0  GROCERY I   \n",
       "3901  125617971 2017-08-16         32     96995            0  GROCERY I   \n",
       "\n",
       "      class  perishable  transactions city state type  cluster  dcoilwtico  \\\n",
       "0      1093           0           NaN  NaN   NaN  NaN      NaN         NaN   \n",
       "3901   1093           0           NaN  NaN   NaN  NaN      NaN         NaN   \n",
       "\n",
       "      week  dow  dayofyear  dayoff  perishable_w  \n",
       "0       33    2        228   False           1.0  \n",
       "3901    33    2        228   False           1.0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[(test.date=='2017-08-16') & (test.item_nbr==96995)]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a_date = test.date.min()\n",
    "\n",
    "for index, row in test[test.date==a_date].iterrows():\n",
    "    \n",
    "    tmp = train[(row.date-datetime.timedelta(days=7),float(row.store_nbr),row.item_nbr)].unit_sales\n",
    "    \n",
    "    if(len(tmp)>0):\n",
    "        test.loc[index,'lag_7'] = tmp.iloc[-1]\n",
    "    else:\n",
    "        print(row)\n",
    "        msg = \"Missing lag_7 for : (%d,%s,%s)\"%(row.date,row.store_nbr,row.item_nbr)\n",
    "        raise Exception(msg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
