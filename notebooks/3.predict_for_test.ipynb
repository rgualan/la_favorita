{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ff2fd268-839a-4483-8681-3c26914f7d9b",
    "_uuid": "89210ac8934aeaeeaaa2b194439c712aded9e688"
   },
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "75fd2f9a-7297-4203-b8f7-1502f66e0c9e",
    "_kg_hide-output": true,
    "_uuid": "54cda7088daf8d27c5627cb80f9bef15fa30f6e7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA MANIPULATION\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import random \n",
    "import datetime # manipulating date formats\n",
    "\n",
    "# VIZUALIZATION\n",
    "import matplotlib.pyplot as plt # basic plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# SUPERVISED LEARNING\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtypes = {'id':'int64', 'item_nbr':'int32', 'store_nbr':'int8', 'onpromotion':str}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "6eccd50b-c197-4fbb-8f21-dac64e7165d4",
    "_uuid": "2d3b84468f9166e001f7ddf20700ac61030101ee"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-989ce370df10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Reading train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/processed/test.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerge_with_extra_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Reading train\n",
    "test = pd.read_csv('../input/processed/test.csv', dtype=dtypes, parse_dates=['date'])\n",
    "\n",
    "train = merge_with_extra_datasets(train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Plot to show how time series look \n",
    "plt.figure(figsize=(15,7))\n",
    "\n",
    "family = 'GROCERY I'\n",
    "counter = 0\n",
    "\n",
    "for i in train[(train.store_nbr==21) & (train['family']==family)].item_nbr.unique():\n",
    "    tmp = train[(train.store_nbr==21) & (train['family']==family) & (train.item_nbr==i)\n",
    "               & (train.date>'2017-01-01')]\n",
    "    ts = pd.Series(tmp.unit_sales.values, index=tmp.date)\n",
    "    \n",
    "    if len(ts['2017']):\n",
    "        plt.plot(ts['2017'])\n",
    "        counter = counter+1\n",
    "        if counter == 50:\n",
    "            break\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train[train.transactions.isnull()].groupby(['date','store_nbr']).item_nbr.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('id', 0), ('date', 0), ('store_nbr', 0), ('item_nbr', 0), ('unit_sales', 0), ('onpromotion', 0), ('family', 0), ('class', 0), ('perishable', 0), ('transactions', 0), ('city', 0), ('state', 0), ('type', 0), ('cluster', 0), ('dcoilwtico', 0), ('week', 0), ('dow', 0), ('dayofyear', 0), ('dayoff', 0)]\n"
     ]
    }
   ],
   "source": [
    "train.dropna(inplace=True)\n",
    "#print([(c,train[c].isnull().sum()) for c in train.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Transform onpromotion\n",
    "def transform_onpromotion(df):\n",
    "    df['onpromotion'] = df['onpromotion'].map({'False': 0, 'True': 1})\n",
    "    return df\n",
    "\n",
    "## Some features were not very useful: year,month,day\n",
    "def add_date_features(df):\n",
    "    #df['year'] = df['date'].dt.year\n",
    "    #df['month'] = df['date'].dt.month\n",
    "    #df['day'] = df['date'].dt.day\n",
    "    df['week'] = df['date'].dt.week\n",
    "    df['dow'] = df['date'].dt.dayofweek\n",
    "    df['dayofyear'] = df['date'].dt.dayofyear\n",
    "    df['dayoff']=[x in [5,6] for x in df.dow] ## Weekends\n",
    "    return df\n",
    "\n",
    "## Transform target variable\n",
    "def transform_unit_sales(df):\n",
    "    df.loc[df.unit_sales < 0., 'unit_sales'] = 0.\n",
    "    df['unit_sales'] = np.log1p(df.unit_sales)\n",
    "    return df\n",
    "\n",
    "## Categorical features\n",
    "def encode(df, column) -> pd.DataFrame:\n",
    "    one_hot = pd.get_dummies(df[column], drop_first=True, prefix=column)\n",
    "    #return (one_hot - one_hot.mean()) / one_hot.std()\n",
    "    return one_hot\n",
    "\n",
    "def encode_categorical_features(df):\n",
    "    cat_columns = ['item_nbr']\n",
    "    \n",
    "    for column in cat_columns:\n",
    "        column_enc = encode(df, column)\n",
    "        df = pd.concat([df,column_enc], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_weigth_feature(df):\n",
    "    df['perishable_w'] = df['perishable'].map({0:1.0, 1:1.25})\n",
    "    return df\n",
    "\n",
    "\n",
    "train = transform_unit_sales(train)\n",
    "train = transform_onpromotion(train)\n",
    "train = add_date_features(train)\n",
    "train = add_weigth_feature(train)\n",
    "#train = encode_categorical_features(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "store_nbr  item_nbr\n",
       "21         103501      575\n",
       "           103520      332\n",
       "           103665      417\n",
       "           105576      581\n",
       "           105693      472\n",
       "           105857      538\n",
       "           106716      543\n",
       "           108079      379\n",
       "           108634      122\n",
       "           108696      541\n",
       "Name: unit_sales, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Count items by store\n",
    "train.groupby(['store_nbr','item_nbr']).unit_sales.size().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            unit_sales     lag_7\n",
      "unit_sales    1.000000  0.580451\n",
      "lag_7         0.580451  1.000000\n",
      "            unit_sales     lag_7\n",
      "unit_sales    1.000000  0.524472\n",
      "lag_7         0.524472  1.000000\n"
     ]
    }
   ],
   "source": [
    "def add_lag_features(df):\n",
    "    \n",
    "    u_store = df.store_nbr.unique()\n",
    "    df_2 = pd.DataFrame()\n",
    "\n",
    "    df['lag_7'] = np.nan\n",
    "    #train['lag_annual'] = np.nan\n",
    "\n",
    "    for s in u_store:\n",
    "        tmp = train[train.store_nbr==s]\n",
    "        u_items = tmp.item_nbr.unique()  \n",
    "        dates_range = pd.date_range(tmp.date.min(), tmp.date.max())\n",
    "\n",
    "        # Reindex by date and item\n",
    "        tmp.set_index([\"date\", \"item_nbr\"], inplace=True)\n",
    "        tmp = tmp.reindex(\n",
    "            pd.MultiIndex.from_product(\n",
    "                [dates_range, u_items],\n",
    "                names=[\"date\", \"item_nbr\"]\n",
    "            )\n",
    "        )\n",
    "        tmp.sort_index(inplace=True)\n",
    "\n",
    "        # Create lag features\n",
    "        tmp['lag_7'] = tmp['unit_sales'].shift(7*len(u_items))\n",
    "\n",
    "        # Delete temporal df \n",
    "        tmp = tmp.reset_index()\n",
    "\n",
    "        # Drop nan in transactions column\n",
    "        tmp.dropna(subset=['unit_sales'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "        # Correlation coefficient\n",
    "        print(tmp[['unit_sales','lag_7']].corr())\n",
    "\n",
    "        df_2 = pd.concat([df_2,tmp])\n",
    "        \n",
    "    return df_2\n",
    "\n",
    "    \n",
    "train = add_lag_features(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "Ignore items which are not in the test data\n",
    "It is necessary to create a stage 2 for creating lag features from seasonal data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the missing data\n",
    "\n",
    "This is necessary in this point, because in the next step a lot of rows will be injected to provide complete time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "md = [(c,train[c].isnull().sum()) for c in train.columns]\n",
    "\n",
    "for a in md:\n",
    "    if a[1]>0:\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop nan in transactions column\n",
    "#train.dropna(subset=['unit_sales'], inplace=True)\n",
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NWRMSLE(y, pred, w):\n",
    "    return metrics.mean_squared_error(y, pred, sample_weight=w)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['onpromotion',\n",
       " 'perishable',\n",
       " 'transactions',\n",
       " 'dcoilwtico',\n",
       " 'week',\n",
       " 'dow',\n",
       " 'dayofyear',\n",
       " 'dayoff',\n",
       " 'lag_7']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [c for c in train if c not in ['id','date','store_nbr','city','state','type','cluster',\n",
    "                                      'item_nbr','family','class', 'perishable_w',\n",
    "                                      'unit_sales']]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X1 = train.loc[(train.date<'2017-08-01') & (train.date>='2016-01-01')]\n",
    "X2 = train.loc[train.date>='2017-08-01'].copy()\n",
    "\n",
    "target_column = 'unit_sales' \n",
    "y1 = X1[target_column].values\n",
    "y2 = X2[target_column].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>perishable</th>\n",
       "      <th>transactions</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>week</th>\n",
       "      <th>dow</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayoff</th>\n",
       "      <th>lag_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21637</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.126891</td>\n",
       "      <td>32.607</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.223156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21639</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.126891</td>\n",
       "      <td>32.607</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.959135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21640</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.126891</td>\n",
       "      <td>32.607</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.457646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21642</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.126891</td>\n",
       "      <td>32.607</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.959135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21643</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.126891</td>\n",
       "      <td>32.607</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.026672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       onpromotion  perishable  transactions  dcoilwtico  week  dow  \\\n",
       "21637          0.0         0.0      7.126891      32.607   1.0  5.0   \n",
       "21639          0.0         1.0      7.126891      32.607   1.0  5.0   \n",
       "21640          0.0         0.0      7.126891      32.607   1.0  5.0   \n",
       "21642          0.0         0.0      7.126891      32.607   1.0  5.0   \n",
       "21643          0.0         0.0      7.126891      32.607   1.0  5.0   \n",
       "\n",
       "       dayofyear dayoff     lag_7  \n",
       "21637        9.0   True  1.223156  \n",
       "21639        9.0   True  0.959135  \n",
       "21640        9.0   True  1.457646  \n",
       "21642        9.0   True  0.959135  \n",
       "21643        9.0   True  1.026672  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1[cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "method =  1\n",
      "Multilayer perceptron (MLP) neural network 01\n",
      "Error: 0.236785\n",
      "\n",
      "method =  2\n",
      "Bagging Regressor 01\n",
      "Error: 0.231168\n",
      "\n",
      "method =  3\n",
      "GradientBoosting 01\n",
      "Error: 0.230324\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "np.random.seed(1122)\n",
    "\n",
    "number_regressors_to_test = 3\n",
    "for method in range(1, number_regressors_to_test+1):\n",
    "    print('\\nmethod = ', method)\n",
    "    \n",
    "    if (method==1):\n",
    "        print('Multilayer perceptron (MLP) neural network 01')\n",
    "        str_method = 'MLP model01'    \n",
    "        r = MLPRegressor(hidden_layer_sizes=(3,), max_iter=100)\n",
    "    if (method==2):\n",
    "        print('Bagging Regressor 01')\n",
    "        str_method = 'BaggingRegressor01'\n",
    "        r = BaggingRegressor(DecisionTreeRegressor(max_depth=6,max_features=0.85))\n",
    "    if (method==3):\n",
    "        print('GradientBoosting 01')\n",
    "        str_method = 'GradientBoosting01'\n",
    "        r = GradientBoostingRegressor()        \n",
    "\n",
    "    r.fit(X1[cols], y1)\n",
    "    yh2 = r.predict(X2[cols])\n",
    "    X2['prediction_%d'%method] = yh2\n",
    "    #m = metrics.mean_squared_error(y2, yh2)**0.5\n",
    "    m = NWRMSLE(y2, yh2, X2['perishable_w'])\n",
    "\n",
    "\n",
    "    print(\"Error: %f\" % (m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>perishable</th>\n",
       "      <th>transactions</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>week</th>\n",
       "      <th>dow</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayoff</th>\n",
       "      <th>lag_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21637</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.126891</td>\n",
       "      <td>32.607</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.223156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21639</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.126891</td>\n",
       "      <td>32.607</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.959135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21640</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.126891</td>\n",
       "      <td>32.607</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.457646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21642</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.126891</td>\n",
       "      <td>32.607</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.959135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21643</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.126891</td>\n",
       "      <td>32.607</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.026672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       onpromotion  perishable  transactions  dcoilwtico  week  dow  \\\n",
       "21637          0.0         0.0      7.126891      32.607   1.0  5.0   \n",
       "21639          0.0         1.0      7.126891      32.607   1.0  5.0   \n",
       "21640          0.0         0.0      7.126891      32.607   1.0  5.0   \n",
       "21642          0.0         0.0      7.126891      32.607   1.0  5.0   \n",
       "21643          0.0         0.0      7.126891      32.607   1.0  5.0   \n",
       "\n",
       "       dayofyear dayoff     lag_7  \n",
       "21637        9.0   True  1.223156  \n",
       "21639        9.0   True  0.959135  \n",
       "21640        9.0   True  1.457646  \n",
       "21642        9.0   True  0.959135  \n",
       "21643        9.0   True  1.026672  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1[cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improvements:\n",
    "- Initial: 0.79\n",
    "- Extra features (sales, items) + lag_7: 0.23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.230324\n"
     ]
    }
   ],
   "source": [
    "## Train best method\n",
    "np.random.seed(1122)\n",
    "r = GradientBoostingRegressor()   \n",
    "r.fit(X1[cols], y1)\n",
    "yh2 = r.predict(X2[cols])\n",
    "m = NWRMSLE(y2, yh2, X2['perishable_w'])\n",
    "print(\"Error: %f\" % (m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(r, open('../input/models/simple.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/test.csv', dtype=dtypes, parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_stores = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create initial dataset\n",
    "dates_range =  pd.date_range('2017-08-16', '2017-08-31')\n",
    "\n",
    "a = pd.DataFrame({'date':dates_range, 'key':0})\n",
    "b = pd.DataFrame({'store_nbr':sorted(u_stores), 'key':0})\n",
    "\n",
    "X3 = a.merge(b, how='outer').drop('key',1)\n",
    "\n",
    "## Pre-processing\n",
    "X3 = merge_sales(X3)\n",
    "add_date_features(X3)\n",
    "enable_holidays(X3)\n",
    "X3 = encode_categorical_features(X3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
