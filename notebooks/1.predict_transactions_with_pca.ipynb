{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d95099e0-7a39-40a8-bacf-2e4c3cfcfb95",
    "_uuid": "feaf5f77881a33c7fb250a7675a52f03e6a2be03"
   },
   "source": [
    "# Problem Description\n",
    "\n",
    "- The competition is called : **Corporacion Favorita Grocery Sales Forecasting**.\n",
    "- The task is to predict sales in the stores of an Ecuadorian supermarket chain so that they can avoid overstocking.\n",
    "- The given data is a table with the following variables/features: date, store id, item id, sales volume, promotion.\n",
    "- We can see the data as N time series, one per (store, item) combination. Many of these time series are most likely correlated to each other and some sort of <b>dimensional reduction</b> will be most welcome here. \n",
    "- The company also offers some other data sets, such as a list of stores, a time series of daily transactions per store, a list of holidays and events, a list of products by category, and the price of oil, of which a good chunk of the ecuadorian economy is allegedly tied to. These are additional tools to simplify and/or enhance the predictions, and some other external data could also be used in this regard. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ff2fd268-839a-4483-8681-3c26914f7d9b",
    "_uuid": "89210ac8934aeaeeaaa2b194439c712aded9e688"
   },
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "75fd2f9a-7297-4203-b8f7-1502f66e0c9e",
    "_kg_hide-output": true,
    "_uuid": "54cda7088daf8d27c5627cb80f9bef15fa30f6e7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DATA MANIPULATION\n",
    "import numpy as np # linear algebra\n",
    "import random as rd\n",
    "import pandas as pd # data processing\n",
    "import datetime # manipulating date formats\n",
    "from operator import add # elementwise addition\n",
    "\n",
    "# VIZUALIZATION\n",
    "import matplotlib.pyplot as plt # basic plotting\n",
    "import seaborn # for prettier plots\n",
    "#import folium # plotting data on interactive maps\n",
    "%matplotlib inline\n",
    "\n",
    "# SUPERVISED LEARNING\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "6eccd50b-c197-4fbb-8f21-dac64e7165d4",
    "_uuid": "2d3b84468f9166e001f7ddf20700ac61030101ee",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading daily transfers per store\n",
    "sales = pd.read_csv('../input/transactions.csv', parse_dates=['date'])\n",
    "\n",
    "# Reading store list\n",
    "stores = pd.read_csv('../input/stores.csv')\n",
    "stores.type=stores.type.astype('category')\n",
    "\n",
    "# Reading the holiday and events schedule\n",
    "holidays=pd.read_csv('../input/holidays_events.csv', parse_dates=['date'])\n",
    "\n",
    "# Reading oil\n",
    "oil=pd.read_csv('../input/processed/oil.csv', parse_dates=['date'])\n",
    "\n",
    "# Merge datasets\n",
    "def merge_sales(sales):\n",
    "    sales=pd.merge(sales,stores,how='left')\n",
    "    sales=pd.merge(sales,oil,how='left')\n",
    "    return sales\n",
    "\n",
    "sales = merge_sales(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "\n",
    "### Date\n",
    "\n",
    "First, let's work on creating features derived from the date, which is expected to be an important field as we are working with time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>transactions</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>dow</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>770</td>\n",
       "      <td>Salinas</td>\n",
       "      <td>Santa Elena</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>93.14</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>2111</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>93.14</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2358</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>93.14</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>3</td>\n",
       "      <td>3487</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>8</td>\n",
       "      <td>93.14</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>4</td>\n",
       "      <td>1922</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "      <td>93.14</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  store_nbr  transactions     city        state type  cluster  \\\n",
       "0 2013-01-01         25           770  Salinas  Santa Elena    D        1   \n",
       "1 2013-01-02          1          2111    Quito    Pichincha    D       13   \n",
       "2 2013-01-02          2          2358    Quito    Pichincha    D       13   \n",
       "3 2013-01-02          3          3487    Quito    Pichincha    D        8   \n",
       "4 2013-01-02          4          1922    Quito    Pichincha    D        9   \n",
       "\n",
       "   dcoilwtico  year  month  day  week  dow  dayofyear  dayoff  \n",
       "0       93.14  2013      1    1     1    1          1   False  \n",
       "1       93.14  2013      1    2     1    2          2   False  \n",
       "2       93.14  2013      1    2     1    2          2   False  \n",
       "3       93.14  2013      1    2     1    2          2   False  \n",
       "4       93.14  2013      1    2     1    2          2   False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_date_features(sales):\n",
    "    sales['year'] = sales['date'].dt.year\n",
    "    sales['month'] = sales['date'].dt.month\n",
    "    sales['day'] = sales['date'].dt.day\n",
    "    sales['week'] = sales['date'].dt.week\n",
    "    sales['dow'] = sales['date'].dt.dayofweek\n",
    "    sales['dayofyear'] = sales['date'].dt.dayofyear\n",
    "    sales['dayoff']=[x in [5,6] for x in sales.dow] ## Weekends\n",
    "\n",
    "add_date_features(sales)\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holiday events\n",
    "This events are expected to be correlated with high volume sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>locale</th>\n",
       "      <th>locale_name</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Manta</td>\n",
       "      <td>Fundacion de Manta</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Cotopaxi</td>\n",
       "      <td>Provincializacion de Cotopaxi</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-04-12</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Cuenca</td>\n",
       "      <td>Fundacion de Cuenca</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-14</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Libertad</td>\n",
       "      <td>Cantonizacion de Libertad</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-04-21</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Riobamba</td>\n",
       "      <td>Cantonizacion de Riobamba</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date     type    locale locale_name                    description  \\\n",
       "0 2012-03-02  Holiday     Local       Manta             Fundacion de Manta   \n",
       "1 2012-04-01  Holiday  Regional    Cotopaxi  Provincializacion de Cotopaxi   \n",
       "2 2012-04-12  Holiday     Local      Cuenca            Fundacion de Cuenca   \n",
       "3 2012-04-14  Holiday     Local    Libertad      Cantonizacion de Libertad   \n",
       "4 2012-04-21  Holiday     Local    Riobamba      Cantonizacion de Riobamba   \n",
       "\n",
       "   transferred  \n",
       "0        False  \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "4        False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holidays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enable all holidays\n",
    "def enable_holidays(sales):\n",
    "    for (d,t,l,n) in zip(holidays.date,holidays.type,holidays.locale,holidays.locale_name):\n",
    "        if t!='Work Day' and t!='Event':  \n",
    "            if l=='National':\n",
    "                sales.loc[sales.date==d,'dayoff']=True\n",
    "            elif l=='Regional':\n",
    "                sales.loc[(sales.date==d)&(sales.state==n),'dayoff']=True\n",
    "            else:\n",
    "                sales.loc[(sales.date==d)&(sales.city==n),'dayoff']=True\n",
    "        else:\n",
    "            sales.loc[(sales.date==d),'dayoff']=False\n",
    "\n",
    "enable_holidays(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>transactions</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>dow</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34431</th>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>1</td>\n",
       "      <td>1534</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>47.587</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34432</th>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>2</td>\n",
       "      <td>2083</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>47.587</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34433</th>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>3</td>\n",
       "      <td>3601</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>8</td>\n",
       "      <td>47.587</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34434</th>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>4</td>\n",
       "      <td>1689</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "      <td>47.587</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34435</th>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>5</td>\n",
       "      <td>1645</td>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>Santo Domingo de los Tsachilas</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>47.587</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  store_nbr  transactions           city  \\\n",
       "34431 2015-01-10          1          1534          Quito   \n",
       "34432 2015-01-10          2          2083          Quito   \n",
       "34433 2015-01-10          3          3601          Quito   \n",
       "34434 2015-01-10          4          1689          Quito   \n",
       "34435 2015-01-10          5          1645  Santo Domingo   \n",
       "\n",
       "                                state type  cluster  dcoilwtico  year  month  \\\n",
       "34431                       Pichincha    D       13      47.587  2015      1   \n",
       "34432                       Pichincha    D       13      47.587  2015      1   \n",
       "34433                       Pichincha    D        8      47.587  2015      1   \n",
       "34434                       Pichincha    D        9      47.587  2015      1   \n",
       "34435  Santo Domingo de los Tsachilas    D        4      47.587  2015      1   \n",
       "\n",
       "       day  week  dow  dayofyear  dayoff  \n",
       "34431   10     2    5         10   False  \n",
       "34432   10     2    5         10   False  \n",
       "34433   10     2    5         10   False  \n",
       "34434   10     2    5         10   False  \n",
       "34435   10     2    5         10   False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Some manual verifications\n",
    "sales.loc[lambda df: df.date=='2015-01-10'].head()\n",
    "#sales.loc[lambda df: (df.date=='2017-04-13') & (df.city=='Cuenca')].head()\n",
    "#sales.loc[lambda df: (df.date=='2013-04-01') & (df.state=='Cotopaxi')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformation\n",
    "def transform_transactions(sales):\n",
    "    sales['transactions'] = np.log1p(sales.transactions)\n",
    "\n",
    "transform_transactions(sales)\n",
    "\n",
    "# Normalized\n",
    "#sales['transactions3'] = (sales['transactions2'] - sales['transactions2'].mean()) / sales['transactions2'].std()\n",
    "# Normalize independently \n",
    "\n",
    "# Histograms\n",
    "#plt.figure(figsize=(15,5))\n",
    "#sales.transactions.hist(ax=plt.subplot(1,3,1))\n",
    "#sales.transactions2.hist(ax=plt.subplot(1,3,2))\n",
    "#sales.transactions3.hist(ax=plt.subplot(1,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Denormalize\n",
    "def denormalize_target(sales, target, transform=False):\n",
    "    target_std = sales['transactions2'].std()\n",
    "    target_mean = sales['transactions2'].mean()\n",
    "\n",
    "    out = target * target_std + target_mean\n",
    "    if transform:\n",
    "        out = np.expm1(out)\n",
    "    \n",
    "    return out\n",
    "    \n",
    "#test = denormalize_target(sales, sales.transactions3, True)\n",
    "#test.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both distributions are skewed. But the transformed looks more normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features\n",
    "\n",
    "Use one-hot encoding for city, state, type.\n",
    "This might create hundreds of features, which could be restricting given the amount of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode(df, column) -> pd.DataFrame:\n",
    "    one_hot = pd.get_dummies(df[column], drop_first=False, prefix=column)\n",
    "    #return (one_hot - one_hot.mean()) / one_hot.std()\n",
    "    return one_hot\n",
    "\n",
    "def encode_categorical_features(sales):\n",
    "    cat_columns = ['store_nbr','city', 'state', 'type']\n",
    "    \n",
    "    for column in cat_columns:\n",
    "        column_enc = encode(sales, column)\n",
    "        sales = pd.concat([sales,column_enc], axis=1)\n",
    "    \n",
    "    return sales\n",
    "\n",
    "\n",
    "sales = encode_categorical_features(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_cols = [c for c in sales.columns if \n",
    "             not c.startswith('store_nbr_') and \n",
    "             not c.startswith('city_') and \n",
    "             not c.startswith('state') and \n",
    "             not c.startswith('type_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lagged features: weekly and annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#u_dates = sales.date.unique() # There are no records for some dates (eg: 25-dic)\n",
    "dates_range =  pd.date_range(sales.date.min(), sales.date.max())\n",
    "u_stores = sales.store_nbr.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              transactions     lag_7\n",
      "transactions      1.000000  0.959216\n",
      "lag_7             0.959216  1.000000\n",
      "              transactions  lag_annual\n",
      "transactions      1.000000    0.961503\n",
      "lag_annual        0.961503    1.000000\n"
     ]
    }
   ],
   "source": [
    "def add_lag_features(sales):\n",
    "    ## Fill missing rows using a product between the stores and the dates (range min-max)\n",
    "    sales2 = sales.copy()\n",
    "    sales2.set_index([\"date\", \"store_nbr\"], inplace=True)\n",
    "    sales2 = sales2.reindex(\n",
    "        pd.MultiIndex.from_product(\n",
    "            [dates_range, u_stores],\n",
    "            names=[\"date\", \"store_nbr\"]\n",
    "        )\n",
    "    )\n",
    "    sales2.sort_index(inplace=True)\n",
    "    #some_cols2 = [c for c in some_cols if c!='date' and c!='store_nbr']\n",
    "    \n",
    "    ## Lag 7\n",
    "    sales2['lag_7']=np.nan\n",
    "    sales2['lag_7']=sales2['transactions'].shift(7*len(u_stores))\n",
    "    print(sales2[['transactions','lag_7']].corr())\n",
    "    \n",
    "    ## Lag 14\n",
    "    #sales2['lag_14']=np.nan\n",
    "    #sales2['lag_14']=sales2['transactions'].shift(14*len(u_stores))\n",
    "    #print(sales2[['transactions','lag_14']].corr())\n",
    "    #It did not reduce error metric\n",
    "    \n",
    "    ## Lag 364\n",
    "    sales2['lag_annual']= np.nan\n",
    "    sales2['lag_annual']= sales2['transactions'].shift(364*len(u_stores)).values\n",
    "    print(sales2[['transactions','lag_annual']].corr())\n",
    "\n",
    "    #sales2['lag_annual']= \\\n",
    "    #    (1 *   sales2['transactions2'].shift(364*len(u_stores)).values + \n",
    "    #     1.5 * sales2['transactions2'].shift(365*len(u_stores)).values + \n",
    "    #     1 *sales2['transactions2'].shift(366*len(u_stores)).values)/3.5\n",
    "    # It was not better than (364 shift)\n",
    "\n",
    "    ## Lag 364*2\n",
    "    #sales2['lag_annual_']= np.nan\n",
    "    #sales2['lag_annual_']= sales2['transactions'].shift(364*2*len(u_stores)).values\n",
    "    #print(sales2[['transactions','lag_annual_']].corr())\n",
    "\n",
    "    # Delete temporal df\n",
    "    sales = sales2.reset_index()\n",
    "    del sales2\n",
    "    return sales\n",
    "\n",
    "\n",
    "sales = add_lag_features(sales)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sales2['lag_annual']=np.nan\n",
    "\n",
    "## Selecting MultiIndex dataframe\n",
    "dateindex = sales2.index.get_level_values('date')\n",
    "storeindex = sales2.index.get_level_values('store_nbr')\n",
    "#sales2.loc[dateindex.year == 2014]\n",
    "#sales2.loc[dateindex == '2017-05-09']\n",
    "#sales2.loc[(dateindex == '2017-05-09') & (storeindex==1)]\n",
    "#sales2.loc[(dateindex.year == 2014) & (storeindex==25)]\n",
    "\n",
    "for year in reversed(range(2014,2018)):\n",
    "    hop = 365\n",
    "    if year==2017: \n",
    "        hop = 366\n",
    "\n",
    "    sales2.loc[dateindex.year.isin([year,year-1]),'lag_annual'] = \\\n",
    "    sales2.loc[dateindex.year.isin([year,year-1]),'transactions2'].shift(hop*len(u_stores))\n",
    "\n",
    "sales2[['transactions2','lag_annual']].corr()\n",
    "\n",
    "# Check\n",
    "# sales2.loc[(dateindex.month==2) & (dateindex.day==2) & (storeindex==25),['transactions2','lag_annual']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why using a simple shift of 364 provides a better R2 metric???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observaciones:\n",
    "- No existe registros para el 25-dic. Esto puede ser debido a que no trabajan en esa fecha \n",
    "- Some stores have a late start / short life\n",
    "- It seems safe to ignore rows with missing data in the lag features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop nan and sort data\n",
    "\n",
    "There is lots of them because of the creation of the lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping nan rows...\n",
      "Before:  (91152, 114)\n",
      "After:  (63254, 114)\n",
      "Sorting\n"
     ]
    }
   ],
   "source": [
    "def clean_data_for_prediction(df):\n",
    "    # Drop\n",
    "    print('Dropping nan rows...')\n",
    "    print(\"Before: \", df.shape)\n",
    "    df.dropna(inplace=True)\n",
    "    print(\"After: \", df.shape)\n",
    "    \n",
    "    # Sort\n",
    "    print('Sorting')\n",
    "    df.sort_values(['store_nbr', 'date'], ascending=[True, True], inplace=True)\n",
    "    df = df.reindex()\n",
    "    \n",
    "    return df\n",
    "\n",
    "sales = clean_data_for_prediction(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28918, 114)\n",
      "(793, 114)\n"
     ]
    }
   ],
   "source": [
    "cols = [c for c in sales if c not in ['date','store_nbr','type','city','state',\n",
    "                                   'transactions','transactions','transactions3',\n",
    "                                   'prediction']]\n",
    "\n",
    "X1 = sales.loc[(sales.date<'2017-08-01') & (sales.date>='2016-01-01')].copy()\n",
    "X2 = sales.loc[sales.date>='2017-08-01'].copy()\n",
    "print(X1.shape)\n",
    "print(X2.shape)\n",
    "\n",
    "target_column = 'transactions' \n",
    "y1 = X1[target_column].values\n",
    "y2 = X2[target_column].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28918, 50)\n",
      "(793, 50)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "pca = decomposition.PCA(n_components=50)\n",
    "pca.fit(X1[cols])\n",
    "X1 = pca.transform(X1[cols])\n",
    "X2 = pca.transform(X2[cols])\n",
    "print(X1.shape)\n",
    "print(X2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "method =  1\n",
      "Multilayer perceptron (MLP) neural network 01\n",
      "Error: 0.080246\n",
      "\n",
      "method =  2\n",
      "Bagging Regressor 01\n",
      "Error: 0.109614\n",
      "\n",
      "method =  3\n",
      "GradientBoosting 01\n",
      "Error: 0.239136\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "np.random.seed(1122)\n",
    "\n",
    "number_regressors_to_test = 3\n",
    "for method in range(1, number_regressors_to_test+1):\n",
    "    print('\\nmethod = ', method)\n",
    "    \n",
    "    if (method==1):\n",
    "        print('Multilayer perceptron (MLP) neural network 01')\n",
    "        str_method = 'MLP model01'    \n",
    "        r = MLPRegressor(hidden_layer_sizes=(3,), max_iter=100)\n",
    "    if (method==2):\n",
    "        print('Bagging Regressor 01')\n",
    "        str_method = 'BaggingRegressor01'\n",
    "        r = BaggingRegressor(DecisionTreeRegressor(max_depth=6,max_features=0.85))        \n",
    "\n",
    "    if (method==3):\n",
    "        np.random.seed(1122)\n",
    "        print('GradientBoosting 01')\n",
    "        str_method = 'GradientBoosting01'\n",
    "        r = GradientBoostingRegressor(n_estimators=85, max_depth=6, learning_rate = 0.01, \n",
    "                                       verbose=0, warm_start=True,\n",
    "                                       subsample= 0.87, max_features = 0.8)        \n",
    "\n",
    "    r.fit(X1, y1)\n",
    "    yh2 = r.predict(X2)\n",
    "    m = metrics.mean_squared_error(y2, yh2)**0.5\n",
    "\n",
    "    print(\"Error: %f\" % (m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "PCA demonstrated that dimensionality reduction and feature selection are very necessary, specially taking into account all the one-hot encoded categorical features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
